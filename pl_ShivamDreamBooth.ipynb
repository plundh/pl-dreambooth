{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plundh/pl-dreambooth/blob/main/pl_ShivamDreamBooth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzM7j0ZSc_9c"
      },
      "source": [
        "This is based off [Shivam Shriraro's repo](https://github.com/ShivamShrirao/diffusers/tree/main/examples/dreambooth), but with a modified notebook.\n",
        "\n",
        "\n",
        "*On your Google Drive:*\n",
        "1. Put your training images in ***dreambooth/training_images/[training_folder_name]***\n",
        "2. Put your class images in ***dreambooth/class_images/[class_folder_name]***\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XU7NuMAA2drw"
      },
      "outputs": [],
      "source": [
        "#@title Check Runtime GPU\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "n6dcjPnnaiCn"
      },
      "outputs": [],
      "source": [
        "#@title #1. Install Requirements\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive if not already mounted\n",
        "gdrive_path = \"/content/google_drive\"\n",
        "if os.path.isdir(gdrive_path):\n",
        "  print(f\"Google Drive  already mounted at '{gdrive_path}'\" )\n",
        "else:\n",
        "  drive.mount(gdrive_path)\n",
        "\n",
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/examples/dreambooth/train_dreambooth.py\n",
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py\n",
        "%pip install -qq git+https://github.com/ShivamShrirao/diffusers\n",
        "%pip install -q -U --pre triton\n",
        "%pip install -q accelerate==0.12.0 transformers ftfy bitsandbytes gradio natsort\n",
        "%pip install -q https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac_various_6/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\n",
        "# These were compiled on Tesla T4, should also work on P100, thanks to https://github.com/metrolobo\n",
        "\n",
        "# If precompiled wheels don't work, install it with the following command. It will take around 40 minutes to compile.\n",
        "# %pip install git+https://github.com/facebookresearch/xformers@1d31a3a#egg=xformers\n",
        "\n",
        "#@markdown You have to: \\\\\n",
        "#@markdown * Be a registered user in Hugging Face Hub and intput your [access token](https://huggingface.co/settings/tokens) here.\n",
        "#@markdown * Accept the model license before downloading or using the Stable Diffusion weights. Visit the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5), read the license and tick the checkbox to agree.  \n",
        "\n",
        "!mkdir -p ~/.huggingface\n",
        "huggingface_token = \"\" #@param {type:\"string\"}\n",
        "!echo -n \"{huggingface_token}\" > ~/.huggingface/token\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5GeU5_MZ77z",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title #2. Training Data and Settings\n",
        "\n",
        "import math\n",
        "import fnmatch\n",
        "import json\n",
        "from collections import Counter\n",
        "from prettytable import PrettyTable\n",
        "from prettytable import SINGLE_BORDER\n",
        "from IPython.display import Markdown as md\n",
        "\n",
        "#@markdown Suggested settings:\n",
        "#@markdown * **10-30** training images\n",
        "#@markdown * **80-120** steps per training image\n",
        "\n",
        "#@markdown \\\n",
        "\n",
        "#@markdown **Training images -**\n",
        "#@markdown _/content/google_drive/MyDrive/dreambooth/training_images/[training_folder_name]_ \\\\\n",
        "training_folder_name = \"azorn\" #@param {type:\"string\"}\n",
        "concept_name = \"AndersZorn\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown If you wish to train multiple concepts, add additional dictionaries to **concepts_input** in the code. \\\\\n",
        "\n",
        "\n",
        "#@markdown \\\n",
        "\n",
        "#@markdown **Class images -**\n",
        "#@markdown _/content/google_drive/MyDrive/dreambooth/class_images/[class_folder_name]_\n",
        "enable_prior_preservation = False #@param {type:\"boolean\"}\n",
        "class_folder_name = \"style_ddimm\" #@param {type:\"string\"}\n",
        "\n",
        "if enable_prior_preservation:\n",
        "  class_name = \"artstyle\" #@param {type:\"string\"}\n",
        "else:\n",
        "  class_name = \"\"\n",
        "\n",
        "#@markdown If no folder is provided, class images will be generated prior to training.\n",
        "\n",
        "training_images_root = gdrive_path + \"/MyDrive/dreambooth/training_images/\"\n",
        "class_images_root = gdrive_path + \"/MyDrive/dreambooth/class_images/\"\n",
        "\n",
        "concepts_list = []\n",
        "\n",
        "concepts_input = [\n",
        "    {\n",
        "        \"concept_name\":                   concept_name,\n",
        "        \"class_name\":                     class_name,\n",
        "        \"training_folder_name\":           training_folder_name,\n",
        "        \"class_folder_name\":              class_folder_name\n",
        "#    },\n",
        "#    {\n",
        "#        \"concept_name\":                  \"JohnSingerSargent\",\n",
        "#        \"class_name\":                    \"artstyle\",\n",
        "#        \"training_folder_name\":          \"jsargent\",\n",
        "#        \"class_folder_name\":             \"style_ddim\"\n",
        "    }\n",
        "]\n",
        "\n",
        "for concept in concepts_input:\n",
        "  instance_values = {\n",
        "        \"instance_prompt\":      concept[\"concept_name\"],\n",
        "        \"instance_data_dir\":    f\"{training_images_root}{concept['training_folder_name']}/\",\n",
        "        \"inst_file_count\":      len(os.listdir(f\"{training_images_root}{concept['training_folder_name']}\")),\n",
        "     }\n",
        "  \n",
        "  if enable_prior_preservation:\n",
        "    class_values ={\n",
        "      \"class_prompt\":         concept[\"class_name\"],\n",
        "      \"class_data_dir\":       f\"{class_images_root}{concept['class_folder_name']}/\",\n",
        "      \"class_file_count\":     len(os.listdir(f\"{class_images_root}{concept['class_folder_name']}\"))\n",
        "    }\n",
        "    combined_values = {**instance_values, **class_values}\n",
        "    concepts_list.append(combined_values)\n",
        "  else:\n",
        "    concepts_list.append(instance_values)\n",
        "\n",
        "if not enable_prior_preservation: print(\"☑️ Skipping Prior Preservation\")\n",
        "\n",
        "#print(json.dumps(concepts_list, sort_keys=True, indent=2)) # For debugging\n",
        "#print(\"\\n\")\n",
        "if len(concepts_list) == 1:\n",
        "    print(\"Training 1 concept\")\n",
        "else:\n",
        "    print(f\"Training {len(concepts_list)} concepts\")\n",
        "\n",
        "for concept in concepts_list:\n",
        "  print(\"\\n\")\n",
        "  class_name = f\"_{concept['class_prompt']}\" if enable_prior_preservation else ''\n",
        "  combined_token = \",\".join([concept['instance_prompt']for concept in concepts_list])\n",
        "  combined_token_class_folder = \",\".join([\"(\" + str(concept['instance_prompt']) + class_name + \"@\" + str(os.path.basename(os.path.normpath(concept['instance_data_dir']))) + \"_\" + str(concept['inst_file_count']) + \"i\" + \")\" for concept in concepts_list])\n",
        "  if concept['inst_file_count'] == 0:\n",
        "    print(f\"❌ No training images found in '{concept['instance_data_dir']}'\")\n",
        "  else:\n",
        "    print(f\"✅ {concept['inst_file_count']} training images found in '{concept['instance_data_dir']}'\")\n",
        "\n",
        "  if enable_prior_preservation:\n",
        "    total_class_images = sum([concept['inst_file_count'] for concept in concepts_list])\n",
        "    if concept['class_file_count'] == 0:\n",
        "          print(f\"❌ Noclass images found in '{concept['class_data_dir']}'\")\n",
        "    else:\n",
        "      print(f\"✅ {concept['class_file_count']} class images found in '{concept['class_data_dir']}'\")\n",
        "\n",
        "  concept_table = PrettyTable(header=False)\n",
        "  concept_table.align = \"l\"\n",
        "  concept_table.set_style(SINGLE_BORDER)\n",
        "\n",
        "  for key, value in concept.items():\n",
        "    concept_table.add_row([key, value])\n",
        "  print(concept_table)\n",
        "\n",
        "with open(\"concepts_list.json\", \"w\") as f:\n",
        "    json.dump(concepts_list, f, indent=4)\n",
        "\n",
        "#if enable_prior_preservation:\n",
        "#  for concept in concepts_list:\n",
        "#    os.makedirs(\"concept['instance_prompt']\", exist_ok=True)\n",
        "\n",
        "#@markdown \\\n",
        "\n",
        "#@markdown **Training Settings**\n",
        "training_steps = 5000 #@param {type:\"integer\"}\n",
        "save_interval = 1000 #@param {type:\"integer\"}\n",
        "pretrained_model_name = \"runwayml/stable-diffusion-v1-5\" #@param [\"runwayml/stable-diffusion-v1-5\", \"compvis/stable-diffusion-v1-4\"]\n",
        "\n",
        "## Output paths\n",
        "date_string = !date +\"%Y-%m-%d_%H-%M\"\n",
        "\n",
        "def output_file_path(training_steps):\n",
        "  return f\"{gdrive_path}/MyDrive/dreambooth/models/{date_string[-1]}_{combined_token_class_folder}_{training_steps}s_pl-shivam.ckpt\"\n",
        "temp_folder = f\"{date_string[-1]}_{combined_token_class_folder}_{training_steps}s\"\n",
        "temp_folder = temp_folder.replace(\" \", \"-\")\n",
        "temp_folder_root = f\"stable_diffusion_weights/{temp_folder}\"\n",
        "\n",
        "!mkdir -p temp_folder\n",
        "!mkdir -p \"{gdrive_path}/MyDrive/dreambooth/models\"\n",
        "\n",
        "total_training_images = sum([concept[\"inst_file_count\"] for concept in concepts_list])\n",
        "\n",
        "checkpoint_steps = training_steps\n",
        "checkpoints_table = PrettyTable(['Step', 'Steps per image'])\n",
        "checkpoints_table.set_style(SINGLE_BORDER)\n",
        "checkpoints_table.sortby = \"Step\"\n",
        "\n",
        "while checkpoint_steps > 0:\n",
        "  steps_per_img = int(checkpoint_steps / total_training_images)\n",
        "  checkpoints_table.add_row([checkpoint_steps, steps_per_img])\n",
        "  checkpoint_steps -= save_interval\n",
        "\n",
        "print(\"\\n\")\n",
        "print(f\"Saving checkpoints every {save_interval} steps:\")\n",
        "print(checkpoints_table)\n",
        "print(\"\\n\")\n",
        "print(\"Ready for training ...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jjcSXTp-u-Eg"
      },
      "outputs": [],
      "source": [
        "#@title #3. Training\n",
        "\n",
        "if enable_prior_preservation:\n",
        "  !accelerate launch train_dreambooth.py \\\n",
        "    --pretrained_model_name_or_path=\"{pretrained_model_name}\" \\\n",
        "    --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\\n",
        "    --output_dir=\"{temp_folder_root}\" \\\n",
        "    --with_prior_preservation \\\n",
        "    --prior_loss_weight=1.0 \\\n",
        "    --num_class_images=\"{total_class_images}\"  \\\n",
        "    --seed=1337 \\\n",
        "    --resolution=512 \\\n",
        "    --train_batch_size=1 \\\n",
        "    --train_text_encoder \\\n",
        "    --mixed_precision=\"fp16\" \\\n",
        "    --use_8bit_adam \\\n",
        "    --gradient_accumulation_steps=1 \\\n",
        "    --learning_rate=1e-6 \\\n",
        "    --lr_scheduler=\"constant\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=\"{training_steps}\" \\\n",
        "    --save_interval=\"{save_interval}\" \\\n",
        "    --concepts_list=\"concepts_list.json\"\n",
        "\n",
        "else:\n",
        "  !accelerate launch train_dreambooth.py \\\n",
        "    --pretrained_model_name_or_path=\"{pretrained_model_name}\" \\\n",
        "    --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\\n",
        "    --output_dir=\"{temp_folder_root}\" \\\n",
        "    --seed=1337 \\\n",
        "    --resolution=512 \\\n",
        "    --train_batch_size=1 \\\n",
        "    --train_text_encoder \\\n",
        "    --mixed_precision=\"fp16\" \\\n",
        "    --use_8bit_adam \\\n",
        "    --gradient_accumulation_steps=1 \\\n",
        "    --learning_rate=1e-6 \\\n",
        "    --lr_scheduler=\"constant\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=\"{training_steps}\" \\\n",
        "    --save_interval=\"{save_interval}\" \\\n",
        "    --concepts_list=\"concepts_list.json\"\n",
        "\n",
        "# Reduce the `--save_interval` to lower than `--max_train_steps` to save weights from intermediate steps.\n",
        "# `--save_sample_prompt` can be same as `--instance_prompt` to generate intermediate samples (saved along with weights in samples directory).\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "89Az5NUxOWdy"
      },
      "outputs": [],
      "source": [
        "#@title #4. Export Checkpoint files to Google Drive\n",
        "from google.colab import runtime\n",
        "from natsort import natsorted\n",
        "from glob import glob\n",
        "import os\n",
        "\n",
        "#@markdown  File name legend: **[date]** \\_( **[token]** @ **[training_image_folder]** \\_ **[image_count]** i)_ **[steps]** s_pl-shivam.ckpt \\\\\n",
        "export_only_last_checkpoint = False #@param {type:\"boolean\"}\n",
        "disconnect_on_completion = False #@param {type:\"boolean\"}\n",
        "half_arg = \"\"\n",
        "fp16 = True\n",
        "if fp16:\n",
        "    half_arg = \"--half\"\n",
        "\n",
        "print(output_file_path(training_steps))\n",
        "\n",
        "def convert_diffusers(checkpoint_folder_name, steps_count):\n",
        "  try:\n",
        "    !python convert_diffusers_to_original_stable_diffusion.py --model_path \"{checkpoint_folder_name}\" --checkpoint_path \"{output_file_path(steps_count)}\" --half\n",
        "    print(f\"✅ Saved model '{output_file_path(steps_count)}'\")\n",
        "  except:\n",
        "    print(f\"❌ Could not save model '{output_file_path(training_steps)}'\")\n",
        "\n",
        "if not export_only_last_checkpoint:\n",
        "  for folder in natsorted(glob(f\"{temp_folder_root}/*/\", recursive = True)):\n",
        "    folder_checkpoint = int((os.path.basename(os.path.normpath(folder))))\n",
        "    if folder_checkpoint not in [0, training_steps]:\n",
        "      convert_diffusers(folder, folder_checkpoint)\n",
        "\n",
        "print(training_steps)\n",
        "print(output_file_path(training_steps))\n",
        "\n",
        "convert_diffusers(natsorted(glob(f\"{temp_folder_root}/*/\", recursive = True))[-1], training_steps)\n",
        "\n",
        "\n",
        "if enable_prior_preservation:\n",
        "  print(f\"To invoke your trained subject, use '{combined_token_class_folder}' in the prompt.\")\n",
        "else:\n",
        "  print(f\"To invoke your trained subject, use '{combined_token}' in the prompt.\")\n",
        "\n",
        "if disconnect_on_completion:\n",
        "  runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}