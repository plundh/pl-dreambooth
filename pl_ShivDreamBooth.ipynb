{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plundh/pl-dreambooth/blob/main/pl_ShivDreamBooth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzM7j0ZSc_9c"
      },
      "source": [
        "This Colab is based off of [Shivam Shriraro's repo](https://github.com/ShivamShrirao/diffusers/tree/main/examples/dreambooth), but with added convenience features.\n",
        "\n",
        "*On your Google Drive:*\n",
        "1. Put your training images in ***dreambooth/training_images/[TRAINING_FOLDER_NAME]***\n",
        "2. Put your class images in ***dreambooth/class_images/[CLASS_FOLDER_NAME]***\n",
        "\n",
        "# Notes\n",
        "* This colab needs a GPU with 15 GB VRAM or more to run.\n",
        "* Images: For objects and faces **10-30** training images are sufficient. For art styles, more are often better.\n",
        "* Steps: **80-160** steps per training image\n",
        "* That said, there is no reliable recipe at this point, so don't expect good results without plenty of experimentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XU7NuMAA2drw"
      },
      "outputs": [],
      "source": [
        "#@title Check Runtime GPU\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TrKW_ncb-put"
      },
      "outputs": [],
      "source": [
        "#@title #1. Settings\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive if not already mounted\n",
        "GDRIVE_PATH = \"/content/google_drive\"\n",
        "if os.path.isdir(GDRIVE_PATH):\n",
        "  print(f\"Google Drive  already mounted at '{GDRIVE_PATH}'\" )\n",
        "else:\n",
        "  drive.mount(GDRIVE_PATH)\n",
        "\n",
        "#@markdown ###**Input Model**\n",
        "#@markdown You have to: \\\\\n",
        "#@markdown * Be a registered user in Hugging Face Hub and intput your [access token](https://huggingface.co/settings/tokens) here.\n",
        "#@markdown * Accept the model license before downloading or using the Stable Diffusion weights. Visit the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5), read the license and tick the checkbox to agree.  \n",
        "HUGGINGFACE_TOKEN = \"\" #@param {type:\"string\"}\n",
        "INPUT_MODEL_NAME = \"runwayml/stable-diffusion-v1-5\" #@param [\"runwayml/stable-diffusion-v1-5\", \"compvis/stable-diffusion-v1-4\"]\n",
        "\n",
        "#@markdown \\\n",
        "#@markdown ###**Training Images**\n",
        "#@markdown _/content/google_drive/MyDrive/dreambooth/training_images/[TRAINING_FOLDER_NAME]_ \\\\\n",
        "TRAINING_FOLDER_NAME = \"azorn\" #@param {type:\"string\"}\n",
        "CONCEPT_NAME = \"AndersZorn\" #@param {type:\"string\"}\n",
        "#@markdown If you wish to train multiple concepts, add additional dictionaries to **concepts_input** in the code. \\\\\n",
        "\n",
        "#@markdown \\\n",
        "#@markdown ###**Class Images**\n",
        "#@markdown _/content/google_drive/MyDrive/dreambooth/class_images/[CLASS_FOLDER_NAME]_ \\\\\n",
        "#@markdown '*Prior Preservation*' uses generated reference images from the concept class to prevent your trained concept from distoring other instances of that class. \\\n",
        "#@markdown If no folder is provided, class images will be generated prior to training.\n",
        "ENABLE_PRIOR_PRESERVATION = False #@param {type:\"boolean\"}\n",
        "CLASS_FOLDER_NAME = \"artstyle_ddim\" #@param {type:\"string\"}\n",
        "\n",
        "if ENABLE_PRIOR_PRESERVATION:\n",
        "  CLASS_NAME = \"artstyle\" #@param {type:\"string\"}\n",
        "else:\n",
        "  CLASS_NAME = \"\"\n",
        "\n",
        "TRAINING_IMAGES_ROOT = GDRIVE_PATH + \"/MyDrive/dreambooth/training_images/\"\n",
        "CLASS_IMAGES_ROOT = GDRIVE_PATH + \"/MyDrive/dreambooth/class_images/\"\n",
        "\n",
        "#@markdown \\\n",
        "#@markdown ###**Training Settings**\n",
        "STEPS_PER_IMAGE = 120 #@param {type:\"integer\"}\n",
        "STEPS_PER_IMAGE_SAVE_INTERVAL = 40 #@param {type:\"integer\"}\n",
        "\n",
        "### CONCEPTS GO HERE #################################################################\n",
        "# Add a new dictionary to 'concepts_input' for each extra concept you wish to train.\n",
        "\n",
        "concepts_input = [\n",
        "    {\n",
        "        \"CONCEPT_NAME\":                   CONCEPT_NAME,\n",
        "        \"class_name\":                     CLASS_NAME,\n",
        "        \"TRAINING_FOLDER_NAME\":           TRAINING_FOLDER_NAME,\n",
        "        \"CLASS_FOLDER_NAME\":              CLASS_FOLDER_NAME\n",
        "#    },\n",
        "#    {\n",
        "#        \"CONCEPT_NAME\":                  \"JohnSingerSargent\",\n",
        "#        \"class_name\":                    \"artstyle\",\n",
        "#        \"TRAINING_FOLDER_NAME\":          \"jsargent\",\n",
        "#        \"CLASS_FOLDER_NAME\":             \"artstyle_ddim\"\n",
        "    }\n",
        "]\n",
        "######################################################################################\n",
        "\n",
        "#@markdown \\\n",
        "#@markdown ###**Export**\n",
        "#@markdown  Checkpoints will be saved as '**[date]** \\_( **[token]** @ **[training_image_folder]** \\_ **[image_count]** i)_ **[total images]** _ **{steps per total images}** .ckpt' \\\\\n",
        "EXPORT_ONLY_LAST_CHECKPOINT = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown \\\n",
        "#@markdown ###**Sample Generation**\n",
        "#@markdown Will generate sample images to test how your model performs. A grid of varying 'steps' and 'CFG' settings will be generated for each checkpoint.\n",
        "ENABLE_SAMPLE_GENERATION = False #@param {type:\"boolean\"}\n",
        "\n",
        "DISCONNECT_ON_COMPLETION = False #@param {type:\"boolean\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "R5GeU5_MZ77z"
      },
      "outputs": [],
      "source": [
        "#@title #2. Verify Settings and Training Data\n",
        "\n",
        "import math\n",
        "import fnmatch\n",
        "import json\n",
        "from collections import Counter\n",
        "from prettytable import PrettyTable\n",
        "from prettytable import SINGLE_BORDER\n",
        "from IPython.display import Markdown as md\n",
        "\n",
        "concepts_list = []\n",
        "\n",
        "for concept in concepts_input:\n",
        "  instance_values = {\n",
        "        \"instance_prompt\":      concept[\"CONCEPT_NAME\"],\n",
        "        \"instance_data_dir\":    f\"{TRAINING_IMAGES_ROOT}{concept['TRAINING_FOLDER_NAME']}/\",\n",
        "        \"inst_file_count\":      len(os.listdir(f\"{TRAINING_IMAGES_ROOT}{concept['TRAINING_FOLDER_NAME']}\")),\n",
        "     }\n",
        "  \n",
        "  if ENABLE_PRIOR_PRESERVATION:\n",
        "    class_values ={\n",
        "      \"class_prompt\":         concept[\"class_name\"],\n",
        "      \"class_data_dir\":       f\"{CLASS_IMAGES_ROOT}{concept['CLASS_FOLDER_NAME']}/\",\n",
        "      \"class_file_count\":     len(os.listdir(f\"{CLASS_IMAGES_ROOT}{concept['CLASS_FOLDER_NAME']}\"))\n",
        "    }\n",
        "    combined_values = {**instance_values, **class_values}\n",
        "    concepts_list.append(combined_values)\n",
        "  else:\n",
        "    concepts_list.append(instance_values)\n",
        "\n",
        "if not ENABLE_PRIOR_PRESERVATION: print(\"☑️ Skipping Prior Preservation\")\n",
        "\n",
        "#print(json.dumps(concepts_list, sort_keys=True, indent=2)) # For debugging\n",
        "#print(\"\\n\")\n",
        "\n",
        "if len(concepts_list) == 1:\n",
        "    print(\"Training 1 concept\")\n",
        "else:\n",
        "    print(f\"Training {len(concepts_list)} concepts\")\n",
        "\n",
        "for concept in concepts_list:\n",
        "  print(\"\\n\")\n",
        "  class_name = f\"_{concept['class_prompt']}\" if ENABLE_PRIOR_PRESERVATION else ''\n",
        "  combined_token = \",\".join([concept['instance_prompt']for concept in concepts_list])\n",
        "  combined_token_class_folder = \",\".join([\"(\" + str(concept['instance_prompt']) + class_name + \"@\" + str(os.path.basename(os.path.normpath(concept['instance_data_dir']))) + \"_\" + str(concept['inst_file_count']) + \"i\" + \")\" for concept in concepts_list])\n",
        "  if concept['inst_file_count'] == 0:\n",
        "    print(f\"❌ No training images found in '{concept['instance_data_dir']}'\")\n",
        "  else:\n",
        "    print(f\"✅ {concept['inst_file_count']} training images found in '{concept['instance_data_dir']}'\")\n",
        "\n",
        "  if ENABLE_PRIOR_PRESERVATION:\n",
        "    if concept['class_file_count'] == 0:\n",
        "          print(f\"❌ No Class images found in '{concept['class_data_dir']}'\")\n",
        "    else:\n",
        "      print(f\"✅ {concept['class_file_count']} class images found in '{concept['class_data_dir']}'\")\n",
        "\n",
        "  concept_table = PrettyTable(header=False)\n",
        "  concept_table.align = \"l\"\n",
        "  concept_table.set_style(SINGLE_BORDER)\n",
        "\n",
        "  for key, value in concept.items():\n",
        "    concept_table.add_row([key, value])\n",
        "  print(concept_table)\n",
        "\n",
        "with open(\"concepts_list.json\", \"w\") as f:\n",
        "    json.dump(concepts_list, f, indent=4)\n",
        "\n",
        "total_class_images = sum([concept['inst_file_count'] for concept in concepts_list])\n",
        "\n",
        "## Output paths\n",
        "total_training_images = sum([concept[\"inst_file_count\"] for concept in concepts_list])\n",
        "date_string = !date +\"%Y-%m-%d_%H-%M\"\n",
        "training_steps = total_training_images * STEPS_PER_IMAGE\n",
        "save_interval = total_training_images * STEPS_PER_IMAGE_SAVE_INTERVAL\n",
        "\n",
        "def output_file_name(steps_per_image):\n",
        "  return f\"{date_string[-1]}_{combined_token_class_folder}_[{total_training_images}]_{{{steps_per_image}}}\"\n",
        "\n",
        "temp_folder = f\"{date_string[-1]}_{combined_token_class_folder}_{training_steps}s\"\n",
        "temp_folder = temp_folder.replace(\" \", \"-\")\n",
        "temp_folder_root = f\"stable_diffusion_weights/{temp_folder}\"\n",
        "\n",
        "!mkdir -p temp_folder\n",
        "!mkdir -p \"{GDRIVE_PATH}/MyDrive/dreambooth/models\"\n",
        "\n",
        "checkpoint_steps = training_steps\n",
        "checkpoints_table = PrettyTable(['Step', 'Steps per image'])\n",
        "checkpoints_table.set_style(SINGLE_BORDER)\n",
        "checkpoints_table.sortby = \"Step\"\n",
        "\n",
        "while checkpoint_steps > 0:\n",
        "  steps_per_img = int(checkpoint_steps / total_training_images)\n",
        "  checkpoints_table.add_row([checkpoint_steps, steps_per_img])\n",
        "  checkpoint_steps -= STEPS_PER_IMAGE_SAVE_INTERVAL * total_training_images\n",
        "\n",
        "print(\"\\n\")\n",
        "print(f\"Saving checkpoints every {STEPS_PER_IMAGE_SAVE_INTERVAL} steps per image:\")\n",
        "print(checkpoints_table)\n",
        "print(\"\\n\")\n",
        "print(\"Ready for training ...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "n6dcjPnnaiCn"
      },
      "outputs": [],
      "source": [
        "#@title #3. Install Requirements\n",
        "\n",
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/examples/dreambooth/train_dreambooth.py\n",
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py\n",
        "%pip install -qq git+https://github.com/ShivamShrirao/diffusers\n",
        "%pip install -q -U --pre triton\n",
        "%pip install -q accelerate==0.12.0 transformers ftfy bitsandbytes gradio natsort\n",
        "%pip install -q https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac_various_6/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\n",
        "# These were compiled on Tesla T4, should also work on P100, thanks to https://github.com/metrolobo\n",
        "\n",
        "# If precompiled wheels don't work, install it with the following command. It will take around 40 minutes to compile.\n",
        "# %pip install git+https://github.com/facebookresearch/xformers@1d31a3a#egg=xformers\n",
        "\n",
        "!mkdir -p ~/.huggingface\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jjcSXTp-u-Eg"
      },
      "outputs": [],
      "source": [
        "#@title #4. Training\n",
        "\n",
        "if ENABLE_PRIOR_PRESERVATION:\n",
        "  !accelerate launch train_dreambooth.py \\\n",
        "    --pretrained_model_name_or_path=\"{INPUT_MODEL_NAME}\" \\\n",
        "    --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\\n",
        "    --output_dir=\"{temp_folder_root}\" \\\n",
        "    --with_prior_preservation \\\n",
        "    --prior_loss_weight=1.0 \\\n",
        "    --num_class_images=1000  \\\n",
        "    --seed=1337 \\\n",
        "    --resolution=512 \\\n",
        "    --train_batch_size=1 \\\n",
        "    --train_text_encoder \\\n",
        "    --mixed_precision=\"fp16\" \\\n",
        "    --use_8bit_adam \\\n",
        "    --gradient_accumulation_steps=1 \\\n",
        "    --learning_rate=1e-6 \\\n",
        "    --lr_scheduler=\"constant\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=\"{training_steps}\" \\\n",
        "    --save_interval=\"{save_interval}\" \\\n",
        "    --pad_tokens \\\n",
        "    --concepts_list=\"concepts_list.json\"\n",
        "\n",
        "else:\n",
        "  !accelerate launch train_dreambooth.py \\\n",
        "    --pretrained_model_name_or_path=\"{INPUT_MODEL_NAME}\" \\\n",
        "    --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\\n",
        "    --output_dir=\"{temp_folder_root}\" \\\n",
        "    --seed=1337 \\\n",
        "    --resolution=512 \\\n",
        "    --train_batch_size=1 \\\n",
        "    --train_text_encoder \\\n",
        "    --mixed_precision=\"fp16\" \\\n",
        "    --use_8bit_adam \\\n",
        "    --gradient_accumulation_steps=1 \\\n",
        "    --learning_rate=1e-6 \\\n",
        "    --lr_scheduler=\"constant\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=\"{training_steps}\" \\\n",
        "    --save_interval=\"{save_interval}\" \\\n",
        "    --pad_tokens \\\n",
        "    --concepts_list=\"concepts_list.json\"\n",
        "\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "89Az5NUxOWdy"
      },
      "outputs": [],
      "source": [
        "#@title #5. Export Checkpoint files to Google Drive\n",
        "from natsort import natsorted\n",
        "from glob import glob\n",
        "import os\n",
        "\n",
        "half_arg = \"\"\n",
        "fp16 = True\n",
        "if fp16:\n",
        "    half_arg = \"--half\"\n",
        "\n",
        "def convert_diffusers(checkpoint_folder_name, steps_per_image):\n",
        "  try:\n",
        "    !python convert_diffusers_to_original_stable_diffusion.py --model_path \"{checkpoint_folder_name}\" --checkpoint_path \"{output_file_name(steps_per_image)}\" --half\n",
        "    print(f\"✅ Saved model '{output_file_name(steps_per_image)}'\")\n",
        "  except:\n",
        "    print(f\"❌ Could not save model '{output_file_name(training_steps)}'\")\n",
        "\n",
        "temp_folders_list = natsorted(glob(f\"{temp_folder_root}/*/\", recursive = True))\n",
        "\n",
        "if not EXPORT_ONLY_LAST_CHECKPOINT:\n",
        "  for folder in temp_folders_list:\n",
        "    folder_checkpoint = int((os.path.basename(os.path.normpath(folder))))\n",
        "    if folder_checkpoint not in [0, training_steps]:\n",
        "      convert_diffusers(folder, int(folder_checkpoint/total_training_images))\n",
        "\n",
        "convert_diffusers(temp_folders_list[-1], int(training_steps/total_training_images))\n",
        "\n",
        "if ENABLE_PRIOR_PRESERVATION:\n",
        "  print(f\"To invoke your trained subject, use '{combined_token_class_folder}' in the prompt.\")\n",
        "else:\n",
        "  print(f\"To invoke your trained subject, use '{combined_token}' in the prompt.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZPEpRCBxaHsj"
      },
      "outputs": [],
      "source": [
        "#@title #5. Generate Sample Images\n",
        "import torch\n",
        "from torch import autocast\n",
        "from PIL import Image\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
        "from IPython.display import display\n",
        "from google.colab import runtime\n",
        "\n",
        "g_cuda = torch.Generator(device='cuda')\n",
        "scheduler = DDIMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", clip_sample=False, set_alpha_to_one=False)\n",
        "\n",
        "def image_grid(imgs, rows, cols):\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "    grid_w, grid_h = grid.size\\\n",
        "    \n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "    return grid\n",
        "\n",
        "if ENABLE_SAMPLE_GENERATION:\n",
        "  SAMPLES_ROOT = f\"{GDRIVE_PATH}/MyDrive/dreambooth/models/samples\"\n",
        "  !mkdir -p \"{samples_root}\"\n",
        "  checkpoints_list = [folder for folder in natsorted(glob(f\"{temp_folder_root}/*/\", recursive = True)) if int((os.path.basename(os.path.normpath(folder)))) != 0]\n",
        "  prompt = f\"{CONCEPT_NAME} painting\"\n",
        "\n",
        "  sample_steps = [5,10,20,40,60,80,100,120,150]\n",
        "  sample_CFG = [3, 6, 9, 12, 15, 18, 21]\n",
        "\n",
        "  images = []\n",
        "\n",
        "  for folder in checkpoints_list:\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(folder, scheduler=scheduler, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
        "    checkpoint_name = int((os.path.basename(os.path.normpath(folder))))\n",
        "    for steps in sample_steps:\n",
        "      for CFG in sample_CFG:\n",
        "        with autocast(\"cuda\"), torch.inference_mode():\n",
        "          image = pipe(\n",
        "              prompt,\n",
        "              height=640,\n",
        "              width=512,\n",
        "              num_images_per_prompt=1,\n",
        "              num_inference_steps=steps,\n",
        "              guidance_scale=CFG,\n",
        "              generator=g_cuda\n",
        "          ).images\n",
        "          images = images + image\n",
        "\n",
        "    grid = image_grid(images, rows=len(sample_CFG), cols=len(sample_steps))\n",
        "    file_path = f'{SAMPLES_ROOT}/{output_file_name(int(checkpoint_name/total_training_images))}.jpg'\n",
        "    grid.save(file_path)\n",
        "    print(f'Saved {file_path}')\n",
        "\n",
        "if DISCONNECT_ON_COMPLETION:\n",
        "  runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}